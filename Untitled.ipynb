{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a32d7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "def connect_mongo():\n",
    "    conn = MongoClient('localhost', 27017)\n",
    "\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5937442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mongo(database, collection):\n",
    "    conn = connect_mongo()\n",
    "    db = conn[database] \n",
    "    data = db[collection]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2befad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(matches):\n",
    "    list_to_df = []\n",
    "    for match_test in matches:\n",
    "        roles = [\"TOP\",\n",
    "            \"JUNGLE\",\n",
    "            \"MIDDLE\",\n",
    "            \"BOTTOM\",\n",
    "            \"UTILITY\",\n",
    "            \"TOP\",\n",
    "            \"JUNGLE\",\n",
    "            \"MIDDLE\",\n",
    "            \"BOTTOM\",\n",
    "            \"UTILITY\"]\n",
    "        try:\n",
    "            #Match feature \n",
    "            Data_Json = {}\n",
    "            Data_Json['matchId'] = match_test['metadata']['matchId']\n",
    "            Data_Json['gameDuration'] = match_test['info']['gameDuration']\n",
    "\n",
    "            #Team feature\n",
    "            for i in match_test['info']['teams']:\n",
    "                team_id = i['teamId']\n",
    "                if team_id == 100:\n",
    "                    team = \"BlueTeam\"\n",
    "                else:\n",
    "                    team = \"RedTeam\"\n",
    "                Data_Json[f\"{team}DragonFirst\"] = i['objectives']['dragon']['first']\n",
    "                # Data_Json[f\"{team}DragonKills\"] = i['objectives']['dragon']['kills']\n",
    "                Data_Json[f\"{team}TowerFirst\"] = i['objectives']['tower']['first']\n",
    "                # Data_Json[f\"{team}TowerKills\"] = i['objectives']['tower']['kills']\n",
    "                Data_Json[f\"{team}HeraldFirst\"] = i['objectives']['riftHerald']['first']\n",
    "                # Data_Json[f\"{team}HeraldKills\"] = i['objectives']['riftHerald']['kills']\n",
    "                Data_Json[f\"{team}InhibitorFirst\"] = i['objectives']['inhibitor']['first']\n",
    "                # Data_Json[f\"{team}InhibitorKills\"] = i['objectives']['inhibitor']['kills']\n",
    "                Data_Json[f\"{team}BaronFirst\"] = i['objectives']['baron']['first']\n",
    "                # Data_Json[f\"{team}BaronKills\"] = i['objectives']['baron']['kills']\n",
    "            \n",
    "            #Team Win\n",
    "            team_win = match_test['info']['teams'][0]['win']\n",
    "            if team_win:\n",
    "                Data_Json['teamWin'] = \"BlueTeam\"\n",
    "            else:\n",
    "                Data_Json['teamWin'] = \"RedTeam\"\n",
    "\n",
    "            #Hero-player feature\n",
    "            for participant in match_test['info']['participants']:\n",
    "                if participant['teamId'] == 100:\n",
    "                    team = \"BlueTeam\"\n",
    "                else:\n",
    "                    team = \"RedTeam\"\n",
    "\n",
    "                Data_Json[f\"{team}_{roles[0]}_championName\"] = participant['championName']\n",
    "                # Data_Json[f\"{team}_{roles[0]}_championId\"] = int(participant['championId'])\n",
    "                # Data_Json[f\"{team}_{roles[0]}_kills\"] = int(participant['kills'])\n",
    "                # Data_Json[f\"{team}_{roles[0]}_deaths\"] = int(participant['deaths'])\n",
    "                # Data_Json[f\"{team}_{roles[0]}_assists\"] = int(participant['assists'])\n",
    "                # Data_Json[f\"{team}_{roles[0]}_visionScore\"] = int(participant['visionScore'])\n",
    "                # Data_Json[f\"{team}_{roles[0]}_goldEarned\"] = int(participant['goldEarned'])\n",
    "                # Data_Json[f\"{team}_{roles[0]}_champLevel\"] = int(participant['champLevel'])\n",
    "                # Data_Json[f\"{team}_{roles[0]}_totalDamageDealt\"] = int(participant['totalDamageDealt'])\n",
    "                roles.pop(0)\n",
    "                \n",
    "            list_to_df.append(Data_Json)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return list_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d018131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'metadata'\n",
      "'metadata'\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "'metadata'\n",
      "'metadata'\n",
      "list index out of range\n",
      "list index out of range\n",
      "'metadata'\n",
      "list index out of range\n",
      "'metadata'\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "matches_br = read_mongo('LeagueOfLegends2', 'Matches').find()\n",
    "list_br = create_dataframe(matches_br)\n",
    "df_br = pd.DataFrame(list_br)\n",
    "df_br.to_csv(\"brazil.csv\", index=False)\n",
    "\n",
    "matches_kr = read_mongo('LeagueOfLegends2', 'Matches_KR').find()\n",
    "list_kr = create_dataframe(matches_kr)\n",
    "df_kr = pd.DataFrame(list_kr)\n",
    "df_kr.to_csv(\"korea.csv\", index=False)\n",
    "\n",
    "matches_na = read_mongo('LeagueOfLegends2', 'Matches_NA').find()\n",
    "list_na = create_dataframe(matches_na)\n",
    "df_na = pd.DataFrame(list_na)\n",
    "df_na.to_csv(\"america.csv\", index=False)\n",
    "\n",
    "df = pd.concat([df_br, df_kr, df_na], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "181989c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_br =  pd.get_dummies(df_br, \n",
    "                   prefix=['BlueTeam_TOP_championName',\n",
    "                        'BlueTeam_JUNGLE_championName',\n",
    "                        'BlueTeam_MIDDLE_championName',\n",
    "                          'BlueTeam_BOTTOM_championName',\n",
    "                          'BlueTeam_UTILITY_championName',\n",
    "                          'RedTeam_TOP_championName',\n",
    "                           'RedTeam_JUNGLE_championName', \n",
    "                          'RedTeam_MIDDLE_championName', \n",
    "                          'RedTeam_BOTTOM_championName', \n",
    "                          'RedTeam_UTILITY_championName',],\n",
    "                   columns=['BlueTeam_TOP_championName',\n",
    "                        'BlueTeam_JUNGLE_championName',\n",
    "                          'BlueTeam_MIDDLE_championName',\n",
    "                          'BlueTeam_BOTTOM_championName',\n",
    "                          'BlueTeam_UTILITY_championName',\n",
    "                          'RedTeam_TOP_championName',\n",
    "                           'RedTeam_JUNGLE_championName',\n",
    "                          'RedTeam_MIDDLE_championName',\n",
    "                          'RedTeam_BOTTOM_championName',\n",
    "                          'RedTeam_UTILITY_championName'])\n",
    "\n",
    "df_na =  pd.get_dummies(df_na, \n",
    "                   prefix=['BlueTeam_TOP_championName',\n",
    "                        'BlueTeam_JUNGLE_championName',\n",
    "                        'BlueTeam_MIDDLE_championName',\n",
    "                          'BlueTeam_BOTTOM_championName',\n",
    "                          'BlueTeam_UTILITY_championName',\n",
    "                          'RedTeam_TOP_championName',\n",
    "                           'RedTeam_JUNGLE_championName', \n",
    "                          'RedTeam_MIDDLE_championName', \n",
    "                          'RedTeam_BOTTOM_championName', \n",
    "                          'RedTeam_UTILITY_championName',],\n",
    "                   columns=['BlueTeam_TOP_championName',\n",
    "                        'BlueTeam_JUNGLE_championName',\n",
    "                          'BlueTeam_MIDDLE_championName',\n",
    "                          'BlueTeam_BOTTOM_championName',\n",
    "                          'BlueTeam_UTILITY_championName',\n",
    "                          'RedTeam_TOP_championName',\n",
    "                           'RedTeam_JUNGLE_championName',\n",
    "                          'RedTeam_MIDDLE_championName',\n",
    "                          'RedTeam_BOTTOM_championName',\n",
    "                          'RedTeam_UTILITY_championName'])\n",
    "\n",
    "df_kr =  pd.get_dummies(df_kr, \n",
    "                   prefix=['BlueTeam_TOP_championName',\n",
    "                        'BlueTeam_JUNGLE_championName',\n",
    "                        'BlueTeam_MIDDLE_championName',\n",
    "                          'BlueTeam_BOTTOM_championName',\n",
    "                          'BlueTeam_UTILITY_championName',\n",
    "                          'RedTeam_TOP_championName',\n",
    "                           'RedTeam_JUNGLE_championName', \n",
    "                          'RedTeam_MIDDLE_championName', \n",
    "                          'RedTeam_BOTTOM_championName', \n",
    "                          'RedTeam_UTILITY_championName',],\n",
    "                   columns=['BlueTeam_TOP_championName',\n",
    "                        'BlueTeam_JUNGLE_championName',\n",
    "                          'BlueTeam_MIDDLE_championName',\n",
    "                          'BlueTeam_BOTTOM_championName',\n",
    "                          'BlueTeam_UTILITY_championName',\n",
    "                          'RedTeam_TOP_championName',\n",
    "                           'RedTeam_JUNGLE_championName',\n",
    "                          'RedTeam_MIDDLE_championName',\n",
    "                          'RedTeam_BOTTOM_championName',\n",
    "                          'RedTeam_UTILITY_championName'])\n",
    "\n",
    "df =  pd.get_dummies(df, \n",
    "                   prefix=['BlueTeam_TOP_championName',\n",
    "                        'BlueTeam_JUNGLE_championName',\n",
    "                        'BlueTeam_MIDDLE_championName',\n",
    "                          'BlueTeam_BOTTOM_championName',\n",
    "                          'BlueTeam_UTILITY_championName',\n",
    "                          'RedTeam_TOP_championName',\n",
    "                           'RedTeam_JUNGLE_championName', \n",
    "                          'RedTeam_MIDDLE_championName', \n",
    "                          'RedTeam_BOTTOM_championName', \n",
    "                          'RedTeam_UTILITY_championName',],\n",
    "                   columns=['BlueTeam_TOP_championName',\n",
    "                        'BlueTeam_JUNGLE_championName',\n",
    "                          'BlueTeam_MIDDLE_championName',\n",
    "                          'BlueTeam_BOTTOM_championName',\n",
    "                          'BlueTeam_UTILITY_championName',\n",
    "                          'RedTeam_TOP_championName',\n",
    "                           'RedTeam_JUNGLE_championName',\n",
    "                          'RedTeam_MIDDLE_championName',\n",
    "                          'RedTeam_BOTTOM_championName',\n",
    "                          'RedTeam_UTILITY_championName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76618b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>gameDuration</th>\n",
       "      <th>BlueTeamDragonFirst</th>\n",
       "      <th>BlueTeamTowerFirst</th>\n",
       "      <th>BlueTeamHeraldFirst</th>\n",
       "      <th>BlueTeamInhibitorFirst</th>\n",
       "      <th>BlueTeamBaronFirst</th>\n",
       "      <th>RedTeamDragonFirst</th>\n",
       "      <th>RedTeamTowerFirst</th>\n",
       "      <th>RedTeamHeraldFirst</th>\n",
       "      <th>...</th>\n",
       "      <th>RedTeam_UTILITY_championName_Yone</th>\n",
       "      <th>RedTeam_UTILITY_championName_Yorick</th>\n",
       "      <th>RedTeam_UTILITY_championName_Yuumi</th>\n",
       "      <th>RedTeam_UTILITY_championName_Zac</th>\n",
       "      <th>RedTeam_UTILITY_championName_Zed</th>\n",
       "      <th>RedTeam_UTILITY_championName_Zeri</th>\n",
       "      <th>RedTeam_UTILITY_championName_Ziggs</th>\n",
       "      <th>RedTeam_UTILITY_championName_Zilean</th>\n",
       "      <th>RedTeam_UTILITY_championName_Zoe</th>\n",
       "      <th>RedTeam_UTILITY_championName_Zyra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR1_2795938302</td>\n",
       "      <td>1421</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BR1_2795853514</td>\n",
       "      <td>1324</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BR1_2795826564</td>\n",
       "      <td>968</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR1_2795812740</td>\n",
       "      <td>1556</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BR1_2795556992</td>\n",
       "      <td>1958</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          matchId  gameDuration  BlueTeamDragonFirst  BlueTeamTowerFirst  \\\n",
       "0  BR1_2795938302          1421                 True               False   \n",
       "1  BR1_2795853514          1324                 True                True   \n",
       "2  BR1_2795826564           968                False               False   \n",
       "3  BR1_2795812740          1556                False                True   \n",
       "4  BR1_2795556992          1958                False               False   \n",
       "\n",
       "   BlueTeamHeraldFirst  BlueTeamInhibitorFirst  BlueTeamBaronFirst  \\\n",
       "0                False                    True                True   \n",
       "1                 True                    True               False   \n",
       "2                False                   False               False   \n",
       "3                 True                   False               False   \n",
       "4                False                   False                True   \n",
       "\n",
       "   RedTeamDragonFirst  RedTeamTowerFirst  RedTeamHeraldFirst  ...  \\\n",
       "0               False               True                True  ...   \n",
       "1               False              False               False  ...   \n",
       "2               False               True                True  ...   \n",
       "3                True              False               False  ...   \n",
       "4                True               True                True  ...   \n",
       "\n",
       "   RedTeam_UTILITY_championName_Yone  RedTeam_UTILITY_championName_Yorick  \\\n",
       "0                              False                                False   \n",
       "1                              False                                False   \n",
       "2                              False                                False   \n",
       "3                              False                                False   \n",
       "4                              False                                False   \n",
       "\n",
       "  RedTeam_UTILITY_championName_Yuumi  RedTeam_UTILITY_championName_Zac  \\\n",
       "0                              False                             False   \n",
       "1                              False                             False   \n",
       "2                              False                             False   \n",
       "3                               True                             False   \n",
       "4                              False                             False   \n",
       "\n",
       "   RedTeam_UTILITY_championName_Zed  RedTeam_UTILITY_championName_Zeri  \\\n",
       "0                             False                              False   \n",
       "1                             False                              False   \n",
       "2                             False                              False   \n",
       "3                             False                              False   \n",
       "4                             False                              False   \n",
       "\n",
       "   RedTeam_UTILITY_championName_Ziggs  RedTeam_UTILITY_championName_Zilean  \\\n",
       "0                               False                                False   \n",
       "1                               False                                False   \n",
       "2                               False                                False   \n",
       "3                               False                                False   \n",
       "4                               False                                False   \n",
       "\n",
       "   RedTeam_UTILITY_championName_Zoe  RedTeam_UTILITY_championName_Zyra  \n",
       "0                             False                              False  \n",
       "1                             False                              False  \n",
       "2                             False                              False  \n",
       "3                             False                              False  \n",
       "4                             False                              False  \n",
       "\n",
       "[5 rows x 1653 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7279e266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"BlueTeamDragonFirst\"] = df[\"BlueTeamDragonFirst\"][0].astype(int)\n",
    "df[\"RedTeamDragonFirst\"] = df[\"RedTeamDragonFirst\"][0].astype(int)\n",
    "\n",
    "df[\"BlueTeamHeraldFirst\"] = df[\"BlueTeamHeraldFirst\"][0].astype(int)\n",
    "df[\"RedTeamHeraldFirst\"] = df[\"RedTeamHeraldFirst\"][0].astype(int)\n",
    "\n",
    "df[\"BlueTeamTowerFirst\"] = df[\"BlueTeamTowerFirst\"][0].astype(int)\n",
    "df[\"RedTeamTowerFirst\"] = df[\"RedTeamTowerFirst\"][0].astype(int)\n",
    "\n",
    "df[\"BlueTeamInhibitorFirst\"] = df[\"BlueTeamInhibitorFirst\"][0].astype(int)\n",
    "df[\"RedTeamInhibitorFirst\"] = df[\"RedTeamInhibitorFirst\"][0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d53baa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorias encontradas: ['BlueTeam' 'RedTeam']\n",
      "Exemplo de encode de: 0 e seu valor real: ['BlueTeam']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df['teamWin'] = label_encoder.fit_transform(df['teamWin'].values)\n",
    "print(\"Categorias encontradas: {}\".format(label_encoder.classes_))\n",
    "print(\"Exemplo de encode de: {} e seu valor real: {}\".format(df['teamWin'][0], label_encoder.inverse_transform([df['teamWin'][0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1178bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.6750200302679604\n",
      "F1 score: 0.6777880753784369\n",
      "Recall score: 0.6800991940483571\n",
      "Confusion matrix:\n",
      " [[7486 3689]\n",
      " [3612 7679]]\n",
      "Acurácia média: 67.01%\n",
      "Desvio padrão: 0.41%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "X = df.drop(['teamWin', 'matchId'], axis=1)\n",
    "y = df['teamWin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Garante a nao aleatoridade dos dados/ PCA /Otimizaçao de parametros - existe pronto\n",
    "\n",
    "# cria o modelo de árvore de decisão\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# treina o modelo com os dados de treinamento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# faz previsões com os dados de teste\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# avalia a acurácia do modelo\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica F1\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Acurácia:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall score:', recall)\n",
    "print('Confusion matrix:\\n', confusion)\n",
    "\n",
    "#Cross Validation\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Imprimir as métricas de avaliação médias\n",
    "print(\"Acurácia média: {:.2f}%\".format(scores.mean() * 100))\n",
    "print(\"Desvio padrão: {:.2f}%\".format(scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d873554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "X = df.drop(['teamWin', 'matchId'], axis=1)\n",
    "y = df['teamWin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Garante a nao aleatoridade dos dados/ PCA /Otimizaçao de parametros - existe pronto\n",
    "\n",
    "# cria o modelo de árvore de decisão\n",
    "svc = SVC()\n",
    "\n",
    "# treina o modelo com os dados de treinamento\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# faz previsões com os dados de teste\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# avalia a acurácia do modelo\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica F1\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Acurácia:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall score:', recall)\n",
    "print('Confusion matrix:\\n', confusion)\n",
    "\n",
    "#Cross Validation\n",
    "scores = cross_val_score(svc, X, y, cv=5)\n",
    "\n",
    "# Imprimir as métricas de avaliação médias\n",
    "print(\"Acurácia média: {:.2f}%\".format(scores.mean() * 100))\n",
    "print(\"Desvio padrão: {:.2f}%\".format(scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "445f1674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.501557909730259\n",
      "F1 score: 0.6599866399465598\n",
      "Recall score: 0.9625365335222744\n",
      "Confusion matrix:\n",
      " [[  400 10775]\n",
      " [  423 10868]]\n",
      "Acurácia média: 50.63%\n",
      "Desvio padrão: 0.09%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "X = df.drop(['teamWin', 'matchId'], axis=1)\n",
    "y = df['teamWin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Garante a nao aleatoridade dos dados/ PCA /Otimizaçao de parametros - existe pronto\n",
    "\n",
    "# cria o modelo de árvore de decisão\n",
    "nb = GaussianNB()\n",
    "\n",
    "# treina o modelo com os dados de treinamento\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# faz previsões com os dados de teste\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# avalia a acurácia do modelo\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica F1\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Acurácia:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall score:', recall)\n",
    "print('Confusion matrix:\\n', confusion)\n",
    "\n",
    "#Cross Validation\n",
    "scores = cross_val_score(nb, X, y, cv=5)\n",
    "\n",
    "# Imprimir as métricas de avaliação médias\n",
    "print(\"Acurácia média: {:.2f}%\".format(scores.mean() * 100))\n",
    "print(\"Desvio padrão: {:.2f}%\".format(scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d02e28f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.7079586931362949\n",
      "F1 score: 0.6745374274517585\n",
      "Recall score: 0.6021610131963511\n",
      "Confusion matrix:\n",
      " [[9106 2069]\n",
      " [4492 6799]]\n",
      "Acurácia média: 70.12%\n",
      "Desvio padrão: 1.40%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "X = df.drop(['teamWin', 'matchId'], axis=1)\n",
    "y = df['teamWin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Garante a nao aleatoridade dos dados/ PCA /Otimizaçao de parametros - existe pronto\n",
    "\n",
    "# cria o modelo de árvore de decisão\n",
    "mlpc = MLPClassifier()\n",
    "\n",
    "# treina o modelo com os dados de treinamento\n",
    "mlpc.fit(X_train, y_train)\n",
    "\n",
    "# faz previsões com os dados de teste\n",
    "y_pred = mlpc.predict(X_test)\n",
    "\n",
    "# avalia a acurácia do modelo\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica F1\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Acurácia:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall score:', recall)\n",
    "print('Confusion matrix:\\n', confusion)\n",
    "\n",
    "#Cross Validation\n",
    "scores = cross_val_score(mlpc, X, y, cv=5)\n",
    "\n",
    "# Imprimir as métricas de avaliação médias\n",
    "print(\"Acurácia média: {:.2f}%\".format(scores.mean() * 100))\n",
    "print(\"Desvio padrão: {:.2f}%\".format(scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc6301d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.49741832101842787\n",
      "F1 score: 0.0\n",
      "Recall score: 0.0\n",
      "Confusion matrix:\n",
      " [[11175     0]\n",
      " [11291     0]]\n",
      "Acurácia média: 50.37%\n",
      "Desvio padrão: 0.49%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(['teamWin', 'matchId'], axis=1)\n",
    "y = df['teamWin']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Garante a nao aleatoridade dos dados/ PCA /Otimizaçao de parametros - existe pronto\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# cria o modelo de árvore de decisão\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# treina o modelo com os dados de treinamento\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# faz previsões com os dados de teste\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# avalia a acurácia do modelo\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica F1\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Acurácia:', acc)\n",
    "print('F1 score:', f1)\n",
    "print('Recall score:', recall)\n",
    "print('Confusion matrix:\\n', confusion)\n",
    "\n",
    "#Cross Validation\n",
    "scores = cross_val_score(lr, X, y, cv=5)\n",
    "\n",
    "# Imprimir as métricas de avaliação médias\n",
    "print(\"Acurácia média: {:.2f}%\".format(scores.mean() * 100))\n",
    "print(\"Desvio padrão: {:.2f}%\".format(scores.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae68d68",
   "metadata": {},
   "source": [
    "## Salvando CODIGO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33f2537a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     19\u001b[0m \u001b[39m# Faça previsões no conjunto de teste\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     22\u001b[0m \u001b[39m# Calcule a precisão e armazene-a\u001b[39;00m\n\u001b[0;32m     23\u001b[0m precisao \u001b[39m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\tree\\_classes.py:500\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    478\u001b[0m \n\u001b[0;32m    479\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    499\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 500\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[0;32m    501\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m    502\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\tree\\_classes.py:460\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     force_all_finite \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 460\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    461\u001b[0m     X,\n\u001b[0;32m    462\u001b[0m     dtype\u001b[39m=\u001b[39;49mDTYPE,\n\u001b[0;32m    463\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    464\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    465\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    466\u001b[0m )\n\u001b[0;32m    467\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    468\u001b[0m     X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[0;32m    469\u001b[0m ):\n\u001b[0;32m    470\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\sklearn\\utils\\validation.py:838\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[39mif\u001b[39;00m pandas_requires_conversion:\n\u001b[0;32m    834\u001b[0m     \u001b[39m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[0;32m    835\u001b[0m     \u001b[39m# nans\u001b[39;00m\n\u001b[0;32m    836\u001b[0m     \u001b[39m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[0;32m    837\u001b[0m     new_dtype \u001b[39m=\u001b[39m dtype_orig \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m dtype\n\u001b[1;32m--> 838\u001b[0m     array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39;49mastype(new_dtype)\n\u001b[0;32m    839\u001b[0m     \u001b[39m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[0;32m    840\u001b[0m     dtype \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\pandas\\core\\generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6317\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6318\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6319\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6320\u001b[0m     ]\n\u001b[0;32m   6322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6323\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6324\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6327\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    449\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\n\u001b[0;32m    452\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    453\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    454\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    455\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    456\u001b[0m     using_cow\u001b[39m=\u001b[39;49musing_copy_on_write(),\n\u001b[0;32m    457\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(b, f)(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    353\u001b[0m     result_blocks \u001b[39m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    355\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(result_blocks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    491\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 511\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    513\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    515\u001b[0m refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mnumpy_dtype\n\u001b[0;32m    241\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    244\u001b[0m     \u001b[39m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:187\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    184\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     values \u001b[39m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    189\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Andrey-PC\\anaconda3\\envs\\tcc-env\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:138\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    137\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    140\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tamanhos_dataset = [500, 1000, 2000, 5000, 10000, 50000, 112000]\n",
    "precisoes = []\n",
    "\n",
    "for tamanho in tamanhos_dataset:\n",
    "    # Divida o conjunto de dados em treinamento e teste com o tamanho desejado\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1.0 - (tamanho / len(X)), random_state=42)\n",
    "    \n",
    "    # cria o modelo de árvore de decisão\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "    # Treine seu modelo no conjunto de treinamento\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Faça previsões no conjunto de teste\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calcule a precisão e armazene-a\n",
    "    precisao = accuracy_score(y_test, y_pred)\n",
    "    precisoes.append(precisao)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(tamanhos_dataset, precisoes, marker='o', linestyle='-')\n",
    "plt.title('Precisão vs. Tamanho do Conjunto de Dados')\n",
    "plt.xlabel('Tamanho do Conjunto de Dados')\n",
    "plt.ylabel('Precisão')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f6559a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.6686390532544378\n",
      "Recall score: 0.6647058823529411\n",
      "Confusion matrix:\n",
      " [[102  55]\n",
      " [ 57 113]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
    "\n",
    "# Carregar os dados de teste\n",
    "# X_test = ...\n",
    "# y_test = ...\n",
    "\n",
    "# Realizar as predições com o modelo\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calcular a métrica F1\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a métrica recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calcular a matriz de confusão\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('F1 score:', f1)\n",
    "print('Recall score:', recall)\n",
    "print('Confusion matrix:\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "024c8634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 50.84%\n",
      "Desvio padrão: 0.28%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Definir as features e target\n",
    "features = df.drop(['teamWin', 'matchId'], axis=1)\n",
    "target = df['teamWin']\n",
    "\n",
    "\n",
    "# Realizar a validação cruzada com 5 folds\n",
    "scores = cross_val_score(clf, features, target, cv=5)\n",
    "\n",
    "# Imprimir as métricas de avaliação médias\n",
    "print(\"Acurácia média: {:.2f}%\".format(scores.mean() * 100))\n",
    "print(\"Desvio padrão: {:.2f}%\".format(scores.std() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c58f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos dados de treinamento: 0.9620\n",
      "Acurácia nos dados de teste: 0.9631\n",
      "Acurácia média na validação cruzada: 0.5974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "import numpy as np\n",
    "\n",
    "# separando os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# criando modelo de regressão logística\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# treinando o modelo nos dados de treinamento\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# realizando previsões nos dados de teste\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# calculando a acurácia nos dados de treinamento\n",
    "train_acc = lr.score(X_train, y_train)\n",
    "\n",
    "# calculando a acurácia nos dados de teste\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print('Acurácia nos dados de treinamento: {:.4f}'.format(train_acc))\n",
    "print('Acurácia nos dados de teste: {:.4f}'.format(test_acc))\n",
    "\n",
    "# utilizando validação cruzada para avaliar a performance do modelo\n",
    "scores = cross_val_score(lr, X, y, cv=5)\n",
    "\n",
    "print('Acurácia média na validação cruzada: {:.4f}'.format(scores.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e62eae",
   "metadata": {},
   "source": [
    "## Salvando CODIGO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891b2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um objeto para o modelo de árvore de decisão (clf é o modelo criado anteriormente)\n",
    "explainer = shap.Explainer(clf, X_train)\n",
    "\n",
    "# Calcula os Shapley Values para uma amostra específica (neste caso, a primeira amostra dos dados de teste)\n",
    "shap_values = explainer(X_test.iloc[0])\n",
    "\n",
    "# Visualiza o gráfico dos Shapley Values para a primeira amostra\n",
    "shap.plots.waterfall(shap_values[1], max_display=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca77e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar explainer SHAP\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "\n",
    "# calcular SHAP values para todas as amostras de teste\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78dcba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# escolher uma amostra de teste específica\n",
    "sample_idx = 0\n",
    "\n",
    "# plotar força gráfico para amostra selecionada\n",
    "shap.force_plot(explainer.expected_value, shap_values[sample_idx,:], X_test[sample_idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b69f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um objeto para o modelo de árvore de decisão (clf é o modelo criado anteriormente)\n",
    "explainer = shap.Explainer(clf, X_train)\n",
    "\n",
    "# Calcula os Shapley Values para todo o conjunto de teste\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Visualiza o gráfico de resumo dos Shapley Values\n",
    "shap.summary_plot(shap_values, X_test, plot_type='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffafc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn --user\n",
    "\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# Categorizando Time Azul\n",
    "df['BlueTeam_TOP_championID'] = label_encoder.fit_transform(df['BlueTeam_TOP_championName'].values)\n",
    "df = df.drop('BlueTeam_TOP_championName', axis=1)\n",
    "\n",
    "df['BlueTeam_JUNGLE_championID'] = label_encoder.fit_transform(df['BlueTeam_JUNGLE_championName'].values)\n",
    "df = df.drop('BlueTeam_JUNGLE_championName', axis=1)\n",
    "\n",
    "df['BlueTeam_MIDDLE_championID'] = label_encoder.fit_transform(df['BlueTeam_MIDDLE_championName'].values)\n",
    "df = df.drop('BlueTeam_MIDDLE_championName', axis=1)\n",
    "\n",
    "df['BlueTeam_BOTTOM_championID'] = label_encoder.fit_transform(df['BlueTeam_BOTTOM_championName'].values)\n",
    "df = df.drop('BlueTeam_BOTTOM_championName', axis=1)\n",
    "\n",
    "df['BlueTeam_UTILITY_championID'] = label_encoder.fit_transform(df['BlueTeam_UTILITY_championName'].values)\n",
    "df = df.drop('BlueTeam_UTILITY_championName', axis=1)\n",
    "\n",
    "# Categorizando time vermelho\n",
    "df['RedTeam_TOP_championID'] = label_encoder.fit_transform(df['RedTeam_TOP_championName'].values)\n",
    "df = df.drop('RedTeam_TOP_championName', axis=1)\n",
    "\n",
    "df['RedTeam_JUNGLE_championID'] = label_encoder.fit_transform(df['RedTeam_JUNGLE_championName'].values)\n",
    "df = df.drop('RedTeam_JUNGLE_championName', axis=1)\n",
    "\n",
    "df['RedTeam_MIDDLE_championID'] = label_encoder.fit_transform(df['RedTeam_MIDDLE_championName'].values)\n",
    "df = df.drop('RedTeam_MIDDLE_championName', axis=1)\n",
    "\n",
    "df['RedTeam_BOTTOM_championID'] = label_encoder.fit_transform(df['RedTeam_BOTTOM_championName'].values)\n",
    "df = df.drop('RedTeam_BOTTOM_championName', axis=1)\n",
    "\n",
    "df['RedTeam_UTILITY_championID'] = label_encoder.fit_transform(df['RedTeam_UTILITY_championName'].values)\n",
    "df = df.drop('RedTeam_UTILITY_championName', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BlueTeamDragonFirst'] = label_encoder.fit_transform(df['BlueTeamDragonFirst'].values)\n",
    "print(\"Categorias encontradas para RedTeam_UTILITY_championName: {}\".format(label_encoder.classes_))\n",
    "print(\"Exemplo de encode de RedTeam_UTILITY_championName: {} e seu valor real: {}\".format(df['BlueTeamDragonFirst'][0], label_encoder.inverse_transform([teamWinID[0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = read_mongo('LeagueOfLegends', 'Matches').find()\n",
    "match_test = matches[0]\n",
    "teste = {}\n",
    "for i in match_test['info']['teams']:\n",
    "    team_id = i['teamId']\n",
    "    if team_id == 100:\n",
    "        team = \"BlueTeam\"\n",
    "    else:\n",
    "        team = \"RedTeam\"\n",
    "    teste[f\"{team}DragonFirst\"] = i['objectives']['dragon']['first']\n",
    "    teste[f\"{team}DragonKills\"] = i['objectives']['dragon']['kills']\n",
    "    teste[f\"{team}TowerFirst\"] = i['objectives']['tower']['first']\n",
    "    teste[f\"{team}TowerFirst\"] = i['objectives']['tower']['kills']\n",
    "    teste[f\"{team}HeraldFirst\"] = i['objectives']['riftHerald']['first']\n",
    "    teste[f\"{team}HeraldKills\"] = i['objectives']['riftHerald']['kills']\n",
    "    teste[f\"{team}InhibitorFirst\"] = i['objectives']['inhibitor']['first']\n",
    "    teste[f\"{team}InhibitorFirst\"] = i['objectives']['inhibitor']['kills']\n",
    "    teste[f\"{team}BaronFirst\"] = i['objectives']['baron']['first']\n",
    "    teste[f\"{team}BaronFirst\"] = i['objectives']['baron']['kills']\n",
    "\n",
    "print(teste)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37224aed779b8dcc1c9b13c1fb28c9fe84bcdc510523d5639b3ca789a2eb45e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
